{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97a78d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "\n",
    "from iobs.simulators import make_n_disk\n",
    "from iobs.layers import IOBLayer\n",
    "from iobs.models import BaseAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9dc4baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d313ed3",
   "metadata": {},
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec0053da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 28468.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate images\n",
    "dim = 32\n",
    "data = make_n_disk(\n",
    "    n_samples=10000,\n",
    "    n_disks=2,\n",
    "    dim=dim,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6499f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x400 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot examples\n",
    "N, M = 2,8\n",
    "f, axs = plt.subplots(N, M, figsize=(2*M, 2*N))\n",
    "\n",
    "inds = np.random.choice(len(data), size=N*M, replace=False)\n",
    "for i in range(N):\n",
    "    for j in range(M):\n",
    "        axs[i,j].imshow(data[inds[i*N+j]])\n",
    "        axs[i,j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab689c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training, validation, and testing folds via 80-10-10\n",
    "nfolds = 10\n",
    "folds = np.random.choice(nfolds, size=len(data))\n",
    "\n",
    "in_train = folds < nfolds-2\n",
    "in_val = folds == nfolds-2\n",
    "in_test = folds == nfolds-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa6a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and dataloaders\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize(0.5, 0.5)]\n",
    ")\n",
    "itransform = torchvision.transforms.Normalize(-0.5, 2)\n",
    "class SimulatedDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform:\n",
    "            return self.transform(self.data[idx])\n",
    "        return self.data[idx]\n",
    "\n",
    "train_dataset = SimulatedDataset(data[in_train], transform=transform)\n",
    "val_dataset = SimulatedDataset(data[in_val], transform=transform)\n",
    "test_dataset = SimulatedDataset(data[in_test], transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e7cf52",
   "metadata": {},
   "source": [
    "# Define encoder-decoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba6f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dense_sequence(shape_list):\n",
    "    \"\"\"Convenience function for building a sequence of dense (Linear) layers\"\"\"\n",
    "    layers = []\n",
    "    for i in range(len(shape_list) - 1):\n",
    "        layers += [\n",
    "            nn.Linear(shape_list[i], shape_list[i+1]),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "    return layers[:-1]  # remove last ReLU\n",
    "\n",
    "# define a convolutional encoder\n",
    "encoder = nn.Sequential(\n",
    "    nn.Conv2d(1, 12, 4, stride=2, padding=1),\n",
    "    nn.ReLU(True),\n",
    "    nn.Conv2d(12, 24, 4, stride=2, padding=1),\n",
    "    nn.ReLU(True),\n",
    "    nn.Conv2d(24, 48, 4, stride=2, padding=1),\n",
    "    nn.ReLU(True),\n",
    "    nn.Flatten(),\n",
    "    *(build_dense_sequence([768, 256, 128, 16])),\n",
    ").to(device)\n",
    "\n",
    "# define a convolutional decoder\n",
    "decoder = nn.Sequential(\n",
    "    *(build_dense_sequence([16, 128, 256, 768])),\n",
    "    nn.Unflatten(dim=1,\n",
    "                 unflattened_size=(48, 4, 4)),\n",
    "    nn.ConvTranspose2d(48, 24, 4,\n",
    "                       stride=2, padding=1),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(12, 1, 4, stride=2, padding=1),\n",
    ").to(device)\n",
    "\n",
    "# define a IOB with a max width of 16 features\n",
    "bottleneck = IOBLayer(16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "992a122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a simple autoencoder model\n",
    "model = BaseAE(\n",
    "    input_shape=(dim, dim),\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    bottleneck=bottleneck\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d80eb883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a criterion for log-likelihood maximization\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def lossfn(model, batch_features):\n",
    "    \"\"\"Loss function for averaging loss over all bottleneck widths evenly\"\"\"\n",
    "    outputs = model.forward_all(batch_features)\n",
    "    target = batch_features.unsqueeze(1).expand(*(outputs.shape))\n",
    "    loss = criterion(outputs, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f989efb6",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f9c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "\n",
    "# training\n",
    "max_epochs = 3000\n",
    "lr = 5e-5\n",
    "\n",
    "# early stopping\n",
    "min_change = 0.0001\n",
    "patience = 20\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc9288",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/3000, loss = 1.296964, val loss = 0.931489\n",
      "epoch : 2/3000, loss = 0.544245, val loss = 0.396093\n",
      "epoch : 3/3000, loss = 0.363472, val loss = 0.347635\n",
      "epoch : 4/3000, loss = 0.335810, val loss = 0.330175\n",
      "epoch : 5/3000, loss = 0.318800, val loss = 0.311835\n",
      "epoch : 6/3000, loss = 0.298568, val loss = 0.291285\n",
      "epoch : 7/3000, loss = 0.284477, val loss = 0.284630\n",
      "epoch : 8/3000, loss = 0.280527, val loss = 0.281736\n",
      "epoch : 9/3000, loss = 0.278024, val loss = 0.279032\n",
      "epoch : 10/3000, loss = 0.271971, val loss = 0.267496\n",
      "epoch : 11/3000, loss = 0.258542, val loss = 0.256539\n",
      "epoch : 12/3000, loss = 0.251639, val loss = 0.252045\n",
      "epoch : 13/3000, loss = 0.247065, val loss = 0.246987\n",
      "epoch : 14/3000, loss = 0.240851, val loss = 0.239926\n",
      "epoch : 15/3000, loss = 0.234564, val loss = 0.233601\n",
      "epoch : 16/3000, loss = 0.228666, val loss = 0.228558\n",
      "epoch : 17/3000, loss = 0.224546, val loss = 0.224458\n",
      "epoch : 18/3000, loss = 0.220261, val loss = 0.219706\n",
      "epoch : 19/3000, loss = 0.215606, val loss = 0.214953\n",
      "epoch : 20/3000, loss = 0.210799, val loss = 0.209837\n",
      "epoch : 21/3000, loss = 0.204964, val loss = 0.203109\n",
      "epoch : 22/3000, loss = 0.198601, val loss = 0.197003\n",
      "epoch : 23/3000, loss = 0.192788, val loss = 0.191411\n",
      "epoch : 24/3000, loss = 0.188079, val loss = 0.186860\n",
      "epoch : 25/3000, loss = 0.184061, val loss = 0.183217\n",
      "epoch : 26/3000, loss = 0.180614, val loss = 0.180040\n",
      "epoch : 27/3000, loss = 0.177559, val loss = 0.177190\n",
      "epoch : 28/3000, loss = 0.174733, val loss = 0.174389\n",
      "epoch : 29/3000, loss = 0.172205, val loss = 0.171983\n",
      "epoch : 30/3000, loss = 0.169684, val loss = 0.169683\n",
      "epoch : 31/3000, loss = 0.167526, val loss = 0.167853\n",
      "epoch : 32/3000, loss = 0.165550, val loss = 0.165963\n",
      "epoch : 33/3000, loss = 0.163751, val loss = 0.164063\n",
      "epoch : 34/3000, loss = 0.162102, val loss = 0.162360\n",
      "epoch : 35/3000, loss = 0.160631, val loss = 0.160966\n",
      "epoch : 36/3000, loss = 0.159334, val loss = 0.159810\n",
      "epoch : 37/3000, loss = 0.158049, val loss = 0.158504\n",
      "epoch : 38/3000, loss = 0.156849, val loss = 0.157513\n",
      "epoch : 39/3000, loss = 0.155745, val loss = 0.156691\n",
      "epoch : 40/3000, loss = 0.154759, val loss = 0.155602\n",
      "epoch : 41/3000, loss = 0.153780, val loss = 0.154536\n",
      "epoch : 42/3000, loss = 0.152792, val loss = 0.153450\n",
      "epoch : 43/3000, loss = 0.151911, val loss = 0.152997\n",
      "epoch : 44/3000, loss = 0.151072, val loss = 0.152133\n",
      "epoch : 45/3000, loss = 0.150257, val loss = 0.151254\n",
      "epoch : 46/3000, loss = 0.149541, val loss = 0.150457\n",
      "epoch : 47/3000, loss = 0.148794, val loss = 0.149940\n",
      "epoch : 48/3000, loss = 0.148040, val loss = 0.149061\n",
      "epoch : 49/3000, loss = 0.147427, val loss = 0.148578\n",
      "epoch : 50/3000, loss = 0.146760, val loss = 0.147997\n",
      "epoch : 51/3000, loss = 0.146093, val loss = 0.147676\n",
      "epoch : 52/3000, loss = 0.145566, val loss = 0.146557\n",
      "epoch : 53/3000, loss = 0.144954, val loss = 0.146307\n",
      "epoch : 54/3000, loss = 0.144385, val loss = 0.145470\n",
      "epoch : 55/3000, loss = 0.143813, val loss = 0.145077\n",
      "epoch : 56/3000, loss = 0.143324, val loss = 0.144636\n",
      "epoch : 57/3000, loss = 0.142875, val loss = 0.144194\n",
      "epoch : 58/3000, loss = 0.142364, val loss = 0.143599\n",
      "epoch : 59/3000, loss = 0.141961, val loss = 0.143170\n",
      "epoch : 60/3000, loss = 0.141432, val loss = 0.142622\n",
      "epoch : 61/3000, loss = 0.141003, val loss = 0.142430\n",
      "epoch : 62/3000, loss = 0.140603, val loss = 0.141828\n",
      "epoch : 63/3000, loss = 0.140209, val loss = 0.141472\n",
      "epoch : 64/3000, loss = 0.139762, val loss = 0.141098\n",
      "epoch : 65/3000, loss = 0.139424, val loss = 0.140768\n",
      "epoch : 66/3000, loss = 0.138942, val loss = 0.140431\n",
      "epoch : 67/3000, loss = 0.138673, val loss = 0.140010\n",
      "epoch : 68/3000, loss = 0.138257, val loss = 0.139683\n",
      "epoch : 69/3000, loss = 0.137866, val loss = 0.139380\n",
      "epoch : 70/3000, loss = 0.137500, val loss = 0.138940\n",
      "epoch : 71/3000, loss = 0.137240, val loss = 0.138759\n",
      "epoch : 72/3000, loss = 0.136846, val loss = 0.138489\n",
      "epoch : 73/3000, loss = 0.136510, val loss = 0.138007\n",
      "epoch : 74/3000, loss = 0.136220, val loss = 0.137647\n",
      "epoch : 75/3000, loss = 0.135835, val loss = 0.137377\n",
      "epoch : 76/3000, loss = 0.135578, val loss = 0.137361\n",
      "epoch : 77/3000, loss = 0.135258, val loss = 0.136831\n",
      "epoch : 78/3000, loss = 0.134990, val loss = 0.136647\n",
      "epoch : 79/3000, loss = 0.134708, val loss = 0.136342\n",
      "epoch : 80/3000, loss = 0.134347, val loss = 0.135978\n",
      "epoch : 81/3000, loss = 0.134148, val loss = 0.135901\n",
      "epoch : 82/3000, loss = 0.133829, val loss = 0.135491\n",
      "epoch : 83/3000, loss = 0.133570, val loss = 0.135335\n",
      "epoch : 84/3000, loss = 0.133290, val loss = 0.134981\n",
      "epoch : 85/3000, loss = 0.132955, val loss = 0.134767\n",
      "epoch : 86/3000, loss = 0.132699, val loss = 0.134422\n",
      "epoch : 87/3000, loss = 0.132437, val loss = 0.134139\n",
      "epoch : 88/3000, loss = 0.132199, val loss = 0.134040\n",
      "epoch : 89/3000, loss = 0.131964, val loss = 0.133823\n",
      "epoch : 90/3000, loss = 0.131649, val loss = 0.133566\n",
      "epoch : 91/3000, loss = 0.131429, val loss = 0.133503\n",
      "epoch : 92/3000, loss = 0.131229, val loss = 0.133280\n",
      "epoch : 93/3000, loss = 0.130966, val loss = 0.132896\n",
      "epoch : 94/3000, loss = 0.130777, val loss = 0.132746\n",
      "epoch : 95/3000, loss = 0.130531, val loss = 0.132509\n",
      "epoch : 96/3000, loss = 0.130327, val loss = 0.132256\n",
      "epoch : 97/3000, loss = 0.130037, val loss = 0.132031\n",
      "epoch : 98/3000, loss = 0.129857, val loss = 0.131715\n",
      "epoch : 99/3000, loss = 0.129511, val loss = 0.131616\n",
      "epoch : 100/3000, loss = 0.129359, val loss = 0.131344\n",
      "epoch : 101/3000, loss = 0.129193, val loss = 0.131183\n",
      "epoch : 102/3000, loss = 0.128998, val loss = 0.131117\n",
      "epoch : 103/3000, loss = 0.128751, val loss = 0.130902\n",
      "epoch : 104/3000, loss = 0.128679, val loss = 0.130669\n",
      "epoch : 105/3000, loss = 0.128333, val loss = 0.130482\n",
      "epoch : 106/3000, loss = 0.128204, val loss = 0.130118\n",
      "epoch : 107/3000, loss = 0.127966, val loss = 0.130111\n",
      "epoch : 108/3000, loss = 0.127681, val loss = 0.129924\n",
      "epoch : 109/3000, loss = 0.127577, val loss = 0.129718\n",
      "epoch : 110/3000, loss = 0.127335, val loss = 0.129663\n",
      "epoch : 111/3000, loss = 0.127146, val loss = 0.129228\n",
      "epoch : 112/3000, loss = 0.126893, val loss = 0.129256\n",
      "epoch : 113/3000, loss = 0.126700, val loss = 0.128959\n",
      "epoch : 114/3000, loss = 0.126456, val loss = 0.128778\n",
      "epoch : 115/3000, loss = 0.126254, val loss = 0.128608\n",
      "epoch : 116/3000, loss = 0.126114, val loss = 0.128449\n",
      "epoch : 117/3000, loss = 0.125805, val loss = 0.127950\n",
      "epoch : 118/3000, loss = 0.125569, val loss = 0.127926\n",
      "epoch : 119/3000, loss = 0.125306, val loss = 0.127567\n",
      "epoch : 120/3000, loss = 0.125123, val loss = 0.127404\n",
      "epoch : 121/3000, loss = 0.124976, val loss = 0.127158\n",
      "epoch : 122/3000, loss = 0.124683, val loss = 0.126954\n",
      "epoch : 123/3000, loss = 0.124466, val loss = 0.126968\n",
      "epoch : 124/3000, loss = 0.124311, val loss = 0.126633\n",
      "epoch : 125/3000, loss = 0.124105, val loss = 0.126552\n",
      "epoch : 126/3000, loss = 0.123954, val loss = 0.126129\n",
      "epoch : 127/3000, loss = 0.123747, val loss = 0.126172\n",
      "epoch : 128/3000, loss = 0.123460, val loss = 0.125886\n",
      "epoch : 129/3000, loss = 0.123324, val loss = 0.125922\n",
      "epoch : 130/3000, loss = 0.123202, val loss = 0.125749\n",
      "epoch : 131/3000, loss = 0.122965, val loss = 0.125391\n",
      "epoch : 132/3000, loss = 0.122774, val loss = 0.125160\n",
      "epoch : 133/3000, loss = 0.122626, val loss = 0.124991\n",
      "epoch : 134/3000, loss = 0.122439, val loss = 0.124655\n",
      "epoch : 135/3000, loss = 0.122169, val loss = 0.124626\n",
      "epoch : 136/3000, loss = 0.121942, val loss = 0.124329\n",
      "epoch : 137/3000, loss = 0.121824, val loss = 0.124168\n",
      "epoch : 138/3000, loss = 0.121680, val loss = 0.124266\n",
      "epoch : 139/3000, loss = 0.121575, val loss = 0.123841\n",
      "epoch : 140/3000, loss = 0.121338, val loss = 0.124077\n",
      "epoch : 141/3000, loss = 0.121181, val loss = 0.123662\n",
      "epoch : 142/3000, loss = 0.121012, val loss = 0.123514\n",
      "epoch : 143/3000, loss = 0.120853, val loss = 0.123361\n",
      "epoch : 144/3000, loss = 0.120696, val loss = 0.123116\n",
      "epoch : 145/3000, loss = 0.120481, val loss = 0.123119\n",
      "epoch : 146/3000, loss = 0.120343, val loss = 0.122612\n",
      "epoch : 147/3000, loss = 0.120148, val loss = 0.122863\n",
      "epoch : 148/3000, loss = 0.119994, val loss = 0.122694\n",
      "epoch : 149/3000, loss = 0.119813, val loss = 0.122459\n",
      "epoch : 150/3000, loss = 0.119721, val loss = 0.122459\n",
      "epoch : 151/3000, loss = 0.119570, val loss = 0.121908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 152/3000, loss = 0.119374, val loss = 0.121920\n",
      "epoch : 153/3000, loss = 0.119316, val loss = 0.121737\n",
      "epoch : 154/3000, loss = 0.119189, val loss = 0.121516\n",
      "epoch : 155/3000, loss = 0.118950, val loss = 0.121351\n",
      "epoch : 156/3000, loss = 0.118839, val loss = 0.121430\n",
      "epoch : 157/3000, loss = 0.118662, val loss = 0.121462\n",
      "epoch : 158/3000, loss = 0.118505, val loss = 0.121218\n",
      "epoch : 159/3000, loss = 0.118363, val loss = 0.120987\n",
      "epoch : 160/3000, loss = 0.118287, val loss = 0.121856\n",
      "epoch : 161/3000, loss = 0.118166, val loss = 0.120524\n",
      "epoch : 162/3000, loss = 0.117919, val loss = 0.120901\n",
      "epoch : 163/3000, loss = 0.117887, val loss = 0.120716\n",
      "epoch : 164/3000, loss = 0.117818, val loss = 0.120508\n",
      "epoch : 165/3000, loss = 0.117583, val loss = 0.120138\n",
      "epoch : 166/3000, loss = 0.117462, val loss = 0.120117\n",
      "epoch : 167/3000, loss = 0.117367, val loss = 0.119999\n",
      "epoch : 168/3000, loss = 0.117206, val loss = 0.119711\n",
      "epoch : 169/3000, loss = 0.117132, val loss = 0.119843\n",
      "epoch : 170/3000, loss = 0.117021, val loss = 0.119726\n",
      "epoch : 171/3000, loss = 0.116885, val loss = 0.119437\n",
      "epoch : 172/3000, loss = 0.116807, val loss = 0.119301\n",
      "epoch : 173/3000, loss = 0.116633, val loss = 0.119224\n",
      "epoch : 174/3000, loss = 0.116518, val loss = 0.119335\n",
      "epoch : 175/3000, loss = 0.116402, val loss = 0.119273\n",
      "epoch : 176/3000, loss = 0.116264, val loss = 0.119192\n",
      "epoch : 177/3000, loss = 0.116183, val loss = 0.119015\n",
      "epoch : 178/3000, loss = 0.116037, val loss = 0.118958\n",
      "epoch : 179/3000, loss = 0.115965, val loss = 0.118834\n",
      "epoch : 180/3000, loss = 0.115896, val loss = 0.118520\n",
      "epoch : 181/3000, loss = 0.115729, val loss = 0.118712\n",
      "epoch : 182/3000, loss = 0.115629, val loss = 0.118403\n",
      "epoch : 183/3000, loss = 0.115498, val loss = 0.118199\n",
      "epoch : 184/3000, loss = 0.115343, val loss = 0.117951\n",
      "epoch : 185/3000, loss = 0.115211, val loss = 0.118008\n",
      "epoch : 186/3000, loss = 0.115127, val loss = 0.118160\n",
      "epoch : 187/3000, loss = 0.115083, val loss = 0.117990\n",
      "epoch : 188/3000, loss = 0.114911, val loss = 0.117622\n",
      "epoch : 189/3000, loss = 0.114751, val loss = 0.117698\n",
      "epoch : 190/3000, loss = 0.114681, val loss = 0.117726\n",
      "epoch : 191/3000, loss = 0.114485, val loss = 0.117402\n",
      "epoch : 192/3000, loss = 0.114373, val loss = 0.117339\n",
      "epoch : 193/3000, loss = 0.114253, val loss = 0.117138\n",
      "epoch : 194/3000, loss = 0.114135, val loss = 0.117223\n",
      "epoch : 195/3000, loss = 0.113981, val loss = 0.116943\n",
      "epoch : 196/3000, loss = 0.113973, val loss = 0.116912\n",
      "epoch : 197/3000, loss = 0.113820, val loss = 0.116949\n",
      "epoch : 198/3000, loss = 0.113741, val loss = 0.116596\n",
      "epoch : 199/3000, loss = 0.113613, val loss = 0.116591\n",
      "epoch : 200/3000, loss = 0.113536, val loss = 0.116592\n",
      "epoch : 201/3000, loss = 0.113368, val loss = 0.116364\n",
      "epoch : 202/3000, loss = 0.113340, val loss = 0.116360\n",
      "epoch : 203/3000, loss = 0.113150, val loss = 0.116054\n",
      "epoch : 204/3000, loss = 0.113087, val loss = 0.116196\n",
      "epoch : 205/3000, loss = 0.113073, val loss = 0.116130\n",
      "epoch : 206/3000, loss = 0.112919, val loss = 0.116037\n",
      "epoch : 207/3000, loss = 0.112859, val loss = 0.116192\n",
      "epoch : 208/3000, loss = 0.112776, val loss = 0.115765\n",
      "epoch : 209/3000, loss = 0.112645, val loss = 0.115895\n",
      "epoch : 210/3000, loss = 0.112614, val loss = 0.115801\n",
      "epoch : 211/3000, loss = 0.112433, val loss = 0.115515\n",
      "epoch : 212/3000, loss = 0.112258, val loss = 0.115283\n",
      "epoch : 213/3000, loss = 0.112271, val loss = 0.115316\n",
      "epoch : 214/3000, loss = 0.112118, val loss = 0.115420\n",
      "epoch : 215/3000, loss = 0.112103, val loss = 0.115121\n",
      "epoch : 216/3000, loss = 0.111935, val loss = 0.115346\n",
      "epoch : 217/3000, loss = 0.111869, val loss = 0.114799\n",
      "epoch : 218/3000, loss = 0.111718, val loss = 0.115105\n",
      "epoch : 219/3000, loss = 0.111661, val loss = 0.114791\n",
      "epoch : 220/3000, loss = 0.111577, val loss = 0.114962\n",
      "epoch : 221/3000, loss = 0.111440, val loss = 0.114767\n",
      "epoch : 222/3000, loss = 0.111404, val loss = 0.114924\n",
      "epoch : 223/3000, loss = 0.111320, val loss = 0.114524\n",
      "epoch : 224/3000, loss = 0.111255, val loss = 0.114442\n",
      "epoch : 225/3000, loss = 0.111176, val loss = 0.114286\n",
      "epoch : 226/3000, loss = 0.111037, val loss = 0.114179\n",
      "epoch : 227/3000, loss = 0.110910, val loss = 0.114137\n",
      "epoch : 228/3000, loss = 0.110863, val loss = 0.113886\n",
      "epoch : 229/3000, loss = 0.110748, val loss = 0.113755\n"
     ]
    }
   ],
   "source": [
    "trloss_rec = []\n",
    "valoss_rec = []\n",
    "wait = 0\n",
    "min_valoss = np.inf\n",
    "for epoch in range(max_epochs):\n",
    "    # train\n",
    "    trloss = 0\n",
    "    for batch_features in train_loader:\n",
    "        batch_features = batch_features.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = lossfn(model, batch_features)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        trloss += batch_loss.item()\n",
    "    trloss = trloss / len(train_loader)\n",
    "\n",
    "    # test\n",
    "    with torch.no_grad():\n",
    "        valoss = 0\n",
    "        for batch_features in val_loader:\n",
    "            batch_features = batch_features.float().to(device)\n",
    "            batch_loss = lossfn(model, batch_features)\n",
    "            valoss += batch_loss.item()\n",
    "        valoss = valoss / len(val_loader)\n",
    "\n",
    "    # record loss\n",
    "    trloss_rec.append(trloss)\n",
    "    valoss_rec.append(valoss)\n",
    "    print(f\"epoch : {epoch + 1}/{max_epochs}, \"\n",
    "          f\"loss = {trloss:.6f}, val loss = {valoss:.6f}\")\n",
    "    \n",
    "    # compute early stopping\n",
    "    if valoss < min_valoss*(1-min_change):\n",
    "        wait = 0\n",
    "        min_valoss = valoss\n",
    "    else:\n",
    "        wait += 1\n",
    "    if wait >= patience:\n",
    "        print(f'Early stopping at epoch {epoch + 1}/{max_epochs}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss vs. time\n",
    "lenrec = len(trloss_rec)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.semilogy()\n",
    "ax.plot(range(lenrec), trloss_rec, label='train')\n",
    "ax.plot(range(lenrec), valoss_rec, label='validation')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98fda3c",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f79fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed and reconstruct all test images, for all possible bottleneck widths\n",
    "test_data = test_dataset.data\n",
    "recon_data = np.zeros_like(test_data)\n",
    "recon_data = np.repeat(recon_data[:,None,...], repeats=model.latent_dim+1, axis=1)\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for j, batch_features in enumerate(test_loader):\n",
    "        batch_features = batch_features.float().to(device)\n",
    "        recon_data[i:i+len(batch_features)] = \\\n",
    "            itransform(model.forward_all(batch_features).detach().cpu()[:,:,0,...,None])\n",
    "        i += len(batch_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daedaae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show reconstruction examples, as a function of bottleneck width\n",
    "N = 5\n",
    "max_n_open = 9\n",
    "\n",
    "f, axs = plt.subplots(N, max_n_open+2, figsize=(max_n_open*1.2, N))\n",
    "inds = np.random.choice(len(test_data), size=N, replace=False)\n",
    "for i in range(N):\n",
    "    for j in range(max_n_open+1):\n",
    "        axs[i,j].imshow(recon_data[inds[i], j], vmin=0, vmax=1)\n",
    "        axs[i,j].axis('off')   \n",
    "    \n",
    "    axs[i,-1].imshow(test_data[inds[i]], vmin=0, vmax=1)\n",
    "    axs[i,-1].axis('off')\n",
    "        \n",
    "axs[0,-1].set_title('true')\n",
    "for j in range(max_n_open+1):\n",
    "    axs[0,j].set_title(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and plot the % variance explained, as a function of bottlneeck width\n",
    "testvar = np.sum(np.var(test_data, axis=0).shape)\n",
    "test_percerr = np.sum(np.mean((recon_data-test_data[:,None])**2, axis=0), axis=(1,2,3))/testvar\n",
    "\n",
    "f,ax = plt.subplots()\n",
    "ax.semilogy()\n",
    "ax.plot(test_percerr)\n",
    "ax.grid()\n",
    "ax.set_xlim(0, model.latent_dim)\n",
    "ax.set_xlabel('$k$, Number of open bottlenecks')\n",
    "ax.set_ylabel('$\\mathrm{MSE}/\\sigma^2_\\mathrm{pop}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2666d3",
   "metadata": {},
   "source": [
    "# Calculate intrinsic dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff234ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate intrinisic dimensionality\n",
    "\n",
    "p = 0.05  # p-value at which to reject the null hypothesis\n",
    "diff_loglik = -np.diff(test_percerr/2)*len(test_data)\n",
    "intdim = np.argwhere(~(diff_loglik<chi2.isf(p,1))).max()+1\n",
    "print(f'Intrinsic Dimensionality: {intdim}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
